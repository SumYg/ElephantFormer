import argparse
from pathlib import Path
import numpy as np
from typing import List

from elephant_former.data.elephant_parser import parse_iccs_pgn_file, ElephantGame
from elephant_former import constants # For START_TOKEN_ID if needed, and tokenization logic insight

def calculate_token_sequence_length(game: ElephantGame) -> int:
    """
    Calculates the maximum token sequence length for a game based on its parsed moves.
    Each move is assumed to be tokenized into 4 tokens (fx, fy, tx, ty).
    A START_TOKEN is added at the beginning of the sequence.
    """
    num_moves = len(game.parsed_moves)
    # Sequence: <start> + move1_fx + move1_fy + move1_tx + move1_ty + move2_fx + ...
    # The generate_training_sequences_from_game function generates instances where
    # the input sequence *predicts* the Nth move. The longest input sequence
    # for a game will be the one that predicts the *last* move.
    # This sequence will contain the <start> token and all *previous* moves.
    # If a game has M moves, the last training instance will have an input sequence
    # corresponding to M-1 moves.
    # Length = 1 (start_token) + (M-1 moves) * 4 tokens/move.
    # However, the max_seq_len in the dataset is applied to the input_ids.
    # The input_ids in a TrainingInstance from generate_training_sequences_from_game
    # are: [START_TOKEN_ID] + tokens_for_move_0 + tokens_for_move_1 + ... + tokens_for_move_N-1
    # to predict move_N.
    # So, if a game has P parsed_moves, it generates P training instances.
    # The last instance has an input sequence representing P-1 moves.
    # The tokenized length for that input sequence is 1 (for START_TOKEN) + (P-1) * 4.
    # If P=0 (no moves), len = 1. If P=1, len = 1.
    # Let's consider the length of the *full* tokenized game representation,
    # as max_seq_len often refers to the maximum capacity of the model for any sequence.
    # The ElephantChessDataset checks `len(input_ids) > self.max_seq_len`.
    # `input_ids` are generated by `generate_training_sequences_from_game`.
    # The longest `input_ids` sequence for a game with `P` parsed_moves is for predicting the `P`-th move.
    # This sequence contains `START_TOKEN` and `P-1` moves.
    # So, length is `1 + (P-1)*4`. If P=0, num_moves=0, length=1. If P=1, num_moves=1, length=1.
    # This seems correct for what max_seq_len would be compared against.

    if num_moves == 0:
        return 1 # Only START_TOKEN
    return 1 + (num_moves * 4) # START_TOKEN + all moves tokenized

def main():
    parser = argparse.ArgumentParser(description="Inspect sequence length distribution of Elephant Chess games.")
    parser.add_argument("--pgn_file_path", type=str, required=True, help="Path to the PGN file.")
    args = parser.parse_args()

    print(f"Loading games from: {args.pgn_file_path}")
    all_games: List[ElephantGame] = parse_iccs_pgn_file(args.pgn_file_path)

    if not all_games:
        print(f"No games found in {args.pgn_file_path}. Exiting.")
        return

    print(f"Loaded {len(all_games)} games.")

    sequence_lengths = []
    for i, game in enumerate(all_games):
        # The number of tokens in the input sequence is 1 (for START_TOKEN) + num_moves * 4
        # This represents the sequence that would be fed to predict the *next* move after all game moves.
        # Or, more precisely, the longest *input* sequence generated by `generate_training_sequences_from_game`
        # for a game with M moves, has M-1 moves in it (plus START_TOKEN), so its length is 1 + (M-1)*4.
        # The `max_seq_len` argument in `ElephantChessDataset` is used to filter these generated `input_ids`.
        # Let's calculate lengths based on the definition in `generate_training_sequences_from_game` for the *longest possible input sequence from a game*.
        
        num_parsed_moves = len(game.parsed_moves)
        if num_parsed_moves == 0:
            # A game with 0 moves will result in one training instance: ([<start>], dummy_target_for_non_existent_move)
            # The input_ids is just [<start>]. Length is 1.
            # However, generate_training_sequences_from_game iterates game.parsed_moves. If empty, it returns [].
            # ElephantChessDataset filters games by min_game_len_moves (default 2).
            # Let's stick to the number of tokens representing all moves in a game, including the start token.
            # This is 1 (start) + num_moves * 4.
            # This is the length that `max_seq_len` in the model definition (PositionalEncoding) should accommodate.
            # The dataset's max_seq_len is for filtering *training instances*.
            # An instance is (input_tokens_for_N-1_moves, target_for_Nth_move).
            # So, a game with M moves has its longest *input sequence* of length 1 + (M-1)*4.
            # Let's calculate this value.
            if num_parsed_moves < 1 : # Technically, a game needs at least 1 move to generate a target.
                                     # generate_training_sequences_from_game would yield nothing for 0 moves.
                                     # If game has 1 move, it yields ([<start>], target_for_move_1). Length = 1.
                seq_len = 1
            else:
                seq_len = 1 + (num_parsed_moves -1) * 4
        else:
            seq_len = 1 + (num_parsed_moves -1) * 4


        # Let's simplify: the model's max_seq_len is for the input sequence.
        # An input sequence is <start> token + (k-1) moves, to predict the k-th move.
        # The longest such sequence from a game with P moves has P-1 moves. Length = 1 + (P-1)*4.
        # If P=0, no sequences. If P=1, sequence is [<start>], length 1.
        num_actual_moves = len(game.parsed_moves)
        if num_actual_moves == 0:
            # These games might be filtered out by min_game_len_moves in dataset
            # Or generate_training_sequences_from_game might return empty list
            # For the purpose of understanding raw game lengths transformed into potential max model input:
            current_seq_len = 1 # just <start> if we were to try to predict a "first" move that doesn't exist
        else:
            # The longest input sequence generated from this game will have (num_actual_moves - 1) moves in it
            # plus the start token. Each move takes 4 tokens.
            # Example: 1 move game -> input: [<start>], target: move0. Length of input_ids = 1.
            # Example: 2 move game -> instance 1 input: [<start>], target: move0
            #                       -> instance 2 input: [<start>, fx0,fy0,tx0,ty0], target: move1. Length of input_ids = 1+4=5.
            current_seq_len = 1 + (num_actual_moves -1) * 4 if num_actual_moves > 0 else 1
        
        sequence_lengths.append(current_seq_len)
        if (i+1) % 1000 == 0:
            print(f"Processed {i+1}/{len(all_games)} games...")

    if not sequence_lengths:
        print("No sequence lengths calculated. This might happen if all games were empty or filtered.")
        return

    lengths_np = np.array(sequence_lengths)

    print("\n--- Sequence Length Statistics (based on 1 + (num_moves-1)*4 scheme) ---")
    print(f"Min length: {np.min(lengths_np)}")
    print(f"Max length: {np.max(lengths_np)}")
    print(f"Mean length: {np.mean(lengths_np):.2f}")
    print(f"Median length: {np.median(lengths_np)}")
    percentiles = [50, 75, 90, 95, 98, 99, 99.5, 99.9, 100]
    for p in percentiles:
        print(f"{p}th percentile: {np.percentile(lengths_np, p)}")
    
    print("\nNote: 'num_moves' here is the count of parsed moves from PGN.")
    print("The sequence length is calculated as 1 (for START_TOKEN) + (num_moves - 1) * 4 tokens.")
    print("This represents the length of the input token sequence used to predict the last move of a game.")
    print("Games with 0 moves result in a sequence length of 1 for the START_TOKEN.")
    print("This definition matches how `max_seq_len` is used in `ElephantChessDataset` to filter training instances.")


if __name__ == '__main__':
    main() 